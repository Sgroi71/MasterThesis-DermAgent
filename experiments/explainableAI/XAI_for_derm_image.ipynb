{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKWCgRtwZVLE"
   },
   "source": [
    "# Library importing and model configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4UWh1esZVLG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from captum.attr import Occlusion, Saliency, InputXGradient,NoiseTunnel,IntegratedGradients,KernelShap\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.segmentation import slic\n",
    "from skimage.util import img_as_float\n",
    "import sys\n",
    "\n",
    "ROOT = ...\n",
    "sys.path.append(ROOT)\n",
    "\n",
    "\n",
    "from medDerm.agent import *\n",
    "from medDerm.tools import *\n",
    "from medDerm.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwqvTdidZVLG"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "X94j4eVeZVLG"
   },
   "outputs": [],
   "source": [
    "device=\"cuda\"\n",
    "config_path=f\"{ROOT}/checkpoints/exp-HAM+Derm7pt-all+BCN+HAM-bin+DermNet+Fitzpatrick.yaml\"\n",
    "\n",
    "model = load_checkpoint(config_path).to(device)\n",
    "model.eval()\n",
    "head=\"HAM10k\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    " transforms.Resize((224,224)),\n",
    " transforms.ToTensor(),\n",
    "])\n",
    "norm_transform = transforms.Normalize(\n",
    "     mean=[0.485, 0.456, 0.406],\n",
    "     std=[0.229, 0.224, 0.225]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7meqZ6qZVLG"
   },
   "source": [
    "## Load images \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGqD2PLXZVLH"
   },
   "outputs": [],
   "source": [
    "HAMdatasetDir = f\"{ROOT}/datasets/ISIC_ImageNet/\"\n",
    "test_img = Image.open(f'{HAMdatasetDir}ISIC_0034597.jpg').convert('RGB')\n",
    "transformed_img = transform(test_img)\n",
    "input_img = norm_transform(transformed_img)\n",
    "input_img = input_img.unsqueeze(0).to(device)\n",
    "orig_img = np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0))\n",
    "transformed_img=transformed_img.unsqueeze(0).to(device)\n",
    "input_img.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxrHnrlSZVLH"
   },
   "source": [
    "Perform the classifiction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']\n",
    "\n",
    "\n",
    "outputs = model.forward_explanation_tasks(input_img)\n",
    "output=torch.tensor(outputs[head]['predictions'])\n",
    "prediction_score, pred_label_idx = torch.topk(output, 1)\n",
    "\n",
    "pred_label_idx.squeeze_()\n",
    "predicted_label = classes[pred_label_idx.item()]\n",
    "print('Predicted:', predicted_label, '(', prediction_score.squeeze().item(), ')')\n",
    "print(pred_label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ECluKMHZVLH"
   },
   "outputs": [],
   "source": [
    "\n",
    "def forward_model(image: torch.Tensor):\n",
    "    outputs = model.forward_explanation_tasks(image)\n",
    "    predictions = outputs[head]['predictions']# shape: [B, num_classes]\n",
    "    return predictions # shape: [B]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient-based methods:\n",
    "============================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXT5Ah_VZVLI"
   },
   "source": [
    "\n",
    "## Vanilla Gradient\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPm4rVhEZVLI"
   },
   "outputs": [],
   "source": [
    "vanilla_gradient = Saliency(forward_model)\n",
    "attributions_vg = vanilla_gradient.attribute(input_img, target=pred_label_idx)\n",
    "\n",
    "\n",
    "_ = viz.visualize_image_attr_multiple(\n",
    "    np.transpose(attributions_vg.squeeze().cpu().detach().numpy(), (1, 2, 0)),\n",
    "    orig_img,\n",
    "    methods=[\"original_image\", \"masked_image\", \"blended_heat_map\"],\n",
    "    alpha_overlay=0.5,\n",
    "    signs=[\"all\", \"positive\", \"positive\"],\n",
    "    titles=[\"Original\", \"Image masking\", \"Blended heat map\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input x Gradient\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "InXgrad= InputXGradient(forward_model)\n",
    "attributions_ixg = InXgrad.attribute(input_img, target=pred_label_idx)\n",
    "_ = viz.visualize_image_attr_multiple(np.transpose(attributions_ixg.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                        orig_img,\n",
    "                                        methods=[\"original_image\", \"masked_image\", \"blended_heat_map\"],\n",
    "                                        alpha_overlay=0.5,\n",
    "                                        signs=[\"all\", \"positive\", \"positive\"],\n",
    "                                        titles=[\"Original\", \"Image masking\", \"Blended heat map\"]\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With SmoothGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "smoothGrad= NoiseTunnel(InXgrad)\n",
    "attributions_sg = smoothGrad.attribute(\n",
    "    input_img, \n",
    "    stdevs=0.3, \n",
    "    target=pred_label_idx,\n",
    "    nt_samples=30, \n",
    "    nt_samples_batch_size=5)\n",
    "_ = viz.visualize_image_attr_multiple(np.transpose(attributions_sg.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                        orig_img,\n",
    "                                        methods=[\"original_image\", \"masked_image\", \"blended_heat_map\"],\n",
    "                                        alpha_overlay=0.5,\n",
    "                                        signs=[\"all\", \"positive\", \"positive\"],\n",
    "                                        titles=[\"Original\", \"Image masking\", \"Blended heat map\"]\n",
    "                                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Gradients\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "ig = IntegratedGradients(forward_model)\n",
    "\n",
    "attributions_ig = ig.attribute(\n",
    "    input_img, \n",
    "    target=pred_label_idx, \n",
    "    n_steps=200,\n",
    "    internal_batch_size=10)\n",
    "_ = viz.visualize_image_attr_multiple(np.transpose(attributions_ig.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                        orig_img,\n",
    "                                        methods=[\"original_image\", \"masked_image\", \"blended_heat_map\"],\n",
    "                                        alpha_overlay=0.5,\n",
    "                                        signs=[\"all\", \"positive\", \"positive\"],\n",
    "                                        titles=[\"Original\", \"Image masking\", \"Blended heat map\"]\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With SmoothGrad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "smoothGrad_ig= NoiseTunnel(ig)\n",
    "attributions_sg_ig = smoothGrad_ig.attribute(\n",
    "    input_img, \n",
    "    stdevs=0.3, \n",
    "    target=pred_label_idx,\n",
    "    nt_samples=30, \n",
    "    nt_samples_batch_size=5,\n",
    "    n_steps=100,\n",
    "    internal_batch_size=10)\n",
    "_ = viz.visualize_image_attr_multiple(np.transpose(attributions_sg_ig.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                        orig_img,\n",
    "                                        methods=[\"original_image\", \"masked_image\", \"blended_heat_map\"],\n",
    "                                        alpha_overlay=0.5,\n",
    "                                        signs=[\"all\", \"positive\", \"positive\"],\n",
    "                                        titles=[\"Original\", \"Image masking\", \"Blended heat map\"]\n",
    "                                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5Ats9l2ZVLI"
   },
   "source": [
    "Perturbation-based methods\n",
    "=================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occlusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqH8K4x5ZVLI"
   },
   "outputs": [],
   "source": [
    " \n",
    "occlusion = Occlusion(forward_model)\n",
    "\n",
    "\n",
    "attributions_occ = occlusion.attribute(input_img, target=pred_label_idx, sliding_window_shapes=(3, 15, 15), strides=(3, 8, 8))\n",
    "\n",
    "_ = viz.visualize_image_attr_multiple(np.transpose(attributions_occ.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                        orig_img,\n",
    "                                        methods=[\"original_image\", \"masked_image\", \"blended_heat_map\"],\n",
    "                                        alpha_overlay=0.5,\n",
    "                                        signs=[\"all\", \"positive\", \"positive\"],\n",
    "                                        titles=[\"Original\", \"Image masking\", \"Blended heat map\"]\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_mask(input_img):\n",
    "    \n",
    "    orig_img_float = img_as_float(input_img)  # shape (H, W, 3), values in [0, 1]\n",
    "    segments = slic(orig_img_float, n_segments=100, compactness=10)\n",
    "    feature_mask = torch.tensor(segments, dtype=torch.long).to(device)\n",
    "    return feature_mask\n",
    "\n",
    "feature_mask = generate_feature_mask(orig_img)\n",
    "    \n",
    "\n",
    "baseline = torch.zeros_like(transformed_img) + 0.5\n",
    "baseline = baseline.to(device)\n",
    "\n",
    "kernel_shap = KernelShap(forward_model)\n",
    "\n",
    "\n",
    "attributions_ks = kernel_shap.attribute(input_img,\n",
    "                                        target=pred_label_idx,\n",
    "                                        #baselines=baseline,\n",
    "                                        n_samples=400,\n",
    "                                        perturbations_per_eval=32,\n",
    "                                        show_progress=True,\n",
    "                                        feature_mask=feature_mask)\n",
    "\n",
    "\n",
    "_ = viz.visualize_image_attr_multiple(np.transpose(attributions_ks.squeeze().cpu().detach().numpy(), (1, 2, 0)),\n",
    "                                        orig_img,\n",
    "                                        methods=[\"original_image\", \"masked_image\", \"blended_heat_map\"],\n",
    "                                        alpha_overlay=0.5,\n",
    "                                        signs=[\"all\", \"positive\", \"positive\"],\n",
    "                                        titles=[\"Original\", \"Image masking\", \"Blended heat map\"]\n",
    "                                    )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
